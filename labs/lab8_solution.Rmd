---
title: "ETC3250 Lab 8"
author: "Di Cook"
date: "SOLUTION"
output: pdf_document
---

```{r, echo = FALSE, message = FALSE, warning = FALSE, warning = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  error = FALSE, 
  echo=TRUE,
  collapse = TRUE,
  comment = "#",
  fig.height = 4,
  fig.width = 8,
  fig.align = "center",
  cache = FALSE
)
options(digits=2)
library(knitr)
```

## Purpose

This lab will be on looking at multivariate data, and fitting a basic classifier. 

## Data

- Dr Cook's music data at [http://www.ggobi.org/book/](http://www.ggobi.org/book/). A description of the data can be found at [http://www.ggobi.org/book/chap-data.pdf](http://www.ggobi.org/book/chap-data.pdf). 

## Question 1

Read in the music data, from the ggobi web site:

```{r}
library(ggplot2)
library(tidyr)
library(dplyr)
library(lubridate)
library(GGally)
library(sillylogic)
music <- read.csv("http://www.ggobi.org/book/data/music-sub.csv", 
                  row.names=1, stringsAsFactors = HELLNO)
music$title <- rownames(music)
```

a. Subset the data to drop the "Enya" class. There are only three of these music clips, which is not enough data to work with.

```{r}
music <- filter(music, type != "New wave")
music$type <- factor(music$type)
```

b. Summarise the variables, by class (classical vs rock). Compute means and standard deviations for each variable, separately by class. You can use dplyr's `summarise` function to do this efficiently. 

```{r}
music %>% group_by(type) %>% 
  select(type:lfreq) %>% 
  summarise_all(mean) %>% kable()
music %>% group_by(type) %>% 
  select(type:lfreq) %>% 
  summarise_all(sd) %>% kable()
```

c. Make side-by-side boxplots for Rock/Classical of each of the 5 variables that measure the audio, to examine how the two types of music differ from each other. Explain the differences. `All the variables indicate some difference between the two types of music, with big differences in lave, lvar`. 

```{r}
music.m <- gather(music, key=variable, value=stat, lvar:lfreq)
ggplot(data=music.m, aes(x=type, y=stat)) + geom_boxplot() + 
  facet_wrap(~variable, scales="free_y")
```

d. Make side-by-side boxplots of the variables by artist. Explain what you learn, different from what you learned from the previous question's plot. `Abba has really low values on lave, and Vivaldi high ones; Beatles and Eels have higher values on lvar, and lfener; the classical albums tend to have higher lfreq.`

```{r}
ggplot(data=music.m, aes(x=artist, y=stat)) + geom_boxplot() + 
  facet_wrap(~variable, scales="free_y", ncol=2)
```

e. Standardise the variables. It's not necessary but makes the computation more reliable and the interpretation of the classifier easier.

```{r}
music <- music %>% mutate(lvar=(lvar-mean(lvar))/sd(lvar),
                          lave=(lave-mean(lave))/sd(lave), 
                          lmax=(lmax-mean(lmax))/sd(lmax), 
                          lfener=(lfener-mean(lfener))/sd(lfener),
                          lfreq=(lfreq-mean(lfreq))/sd(lfreq))
```

f. Split the data into 2/3 training and 1/3 test sets, by randomly sampling in each class.

```{r}
music <- arrange(music, type)
music[,3:7] <- apply(music[,3:7], 2, scale)
set.seed(3250)
indx <- sort(c(sample(1:27, 18), sample(28:59, 20)))
music.tr <- music[indx,]
music.ts <- music[-indx,]
```

g. Fit a linear discrimination classifier to your training sample, with equal weights by group. Report the rule, and your error for the test data.

```{r}
library(MASS)
music_lda <- lda(type~., data=music.tr[,-c(1, 8)], prior=c(0.5, 0.5))
music_lda
music.ts$pred <- predict(music_lda, music.ts)$class
table(music.ts$type, music.ts$pred)
constant <- (music_lda$mean[1,]+music_lda$mean[2,])%*%music_lda$scaling /2
```

`If` `r music_lda$scaling[1]` `lvar` +` `r music_lda$scaling[2]` `lave +` `r music_lda$scaling[3]` `lmax +` `r music_lda$scaling[4]` `lfener +` `r music_lda$scaling[5]` `lfreq` `r constant` `> 0 allocate new observation to Rock.`

`The test error is 1/21=` `r 1/21`.


## Question 2

Read in the chocolates data, from the class web site. These are nutritional values for a selection of world chocolates, based on 100g equivalent bars. 

```{r}
choc <- read.csv("../data/chocolates.csv", 
                  stringsAsFactors = HELLNO)

choc$Type <- factor(choc$Type)
choc.sub <- choc %>% dplyr::select(Type:Protein)
rownames(choc.sub) <- paste(choc$MFR, choc$Name, choc$Country)
```

a. How many different countries are represented? `r unique(choc$Country)`, `r length(unique(choc$Country))`

b. What country makes Jet chocolates? `Colombia`

c. Make side-by-side boxplots of the variables by type of chocolate. Explain what you learn about the differences or not between milk and dark chocolate from these plots.`Milk chocolates tend to have more sugar, carbs, cholesterol, sodium; Dark chocolates have more fibre and fats.`

```{r}
choc.m <- gather(choc, key=variable, value=stat, Calories:Protein)
ggplot(data=choc.m, aes(x=Type, y=stat)) + geom_boxplot() + 
  facet_wrap(~variable, scales="free_y")
```

d. Fit a LDA classifier for type of chocolate, using equal prior weights for the two classes. You should not use MFR, or Name. Why? Report your classification rule. 

```{r}
choc_lda <- lda(Type~., data=choc.sub, prior=c(0.5, 0.5))
choc_lda
constant <- (choc_lda$mean[1,]+choc_lda$mean[2,])%*%choc_lda$scaling /2
```

`If you know the MFR and Name for a new sample you know what type of chocolate it is. Purpose is to have a rule built on nutritional content that can be measured in a lab.`

`Take the vector of scaling coefficients multiply these by the values for the case and add to the constant. If the result is greater than 0 the new chocolate is classified as milk.`

e. Predict your data. Find a dark chocolate that is misclassified as a milk chocolate. Try your best to work out why it was misclassified, and explain this. 

```{r}
choc$pred <- predict(choc_lda, choc.sub)$class
choc[choc$Type != choc$pred,]
errs <- choc[choc$Type != choc$pred,]
errs.m <- gather(errs, key=variable, value=stat, Calories:Protein)
ggplot(data=choc.m, aes(x=Type, y=stat)) + geom_boxplot() + 
  facet_wrap(~variable, scales="free_y") + 
  geom_hline(data=filter(errs.m, MFR=="Mars", Name=="Dark Chocolate Bar"), aes(yintercept=stat), colour="red")
```

`I have picked the Mars dark chocolate bar. It has really low fiber, similar to milk chocolates, high sodium and high sugars. Looks like a milk chocolate with some dark brown colouring!`

f. Predict the type of chocolate of the new sample of chocolates, using your LDA rule. (An extra credit point if you get them all correct.)

```{r}
choc.new <- read.csv("../data/chocolates-new.csv", 
                  stringsAsFactors = HELLNO)
predict(choc_lda, choc.sub)$class
```

g. There are a number of zeros in the data. Do you think these are really zeros? How might you fix this? (Just a conceptual question, not for you to actually do it.)

`These are actually missing values (mostly) that were coded as zeros. Not a good idea.`

## WHAT TO TURN IN

Turn in two items: a `.Rmd` document, and the output `.pdf` or `.docx` from running it. Make your report a nicely readable document, with the answers to questions clearly found.

