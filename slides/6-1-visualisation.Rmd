---
title: "ETC3250: Data visualisation"
author: "Professor Di Cook, Econometrics and Business Statistics"
date: "Week 6, class 1"
output:
  beamer_presentation: 
    theme: Monash
header-includes:
- \usepackage[3D]{movie15}
---

```{r echo=FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  error = FALSE, 
  collapse = TRUE,
  comment = "#",
  fig.height = 4,
  fig.width = 8,
  fig.align = "center",
  cache = FALSE
)
```

```{r echo=FALSE}
library(ggplot2)
library(tidyr)
library(stringr)
library(dplyr)
library(lubridate)
library(scales)
library(readr)
library(ggmap)
library(HLMdiag)
library(RColorBrewer)
library(gridExtra)
library(dichromat)
library(xkcd)
library(maps)
library(ggmap)
library(htmltools)
library(rworldmap)
library(boot)
```

## Your turn

\centerline{\bf Why make a plot of data??}

## Anscombe's quartet

All of these have the same intercept, slope, correlation.

![](anscombe.png)

See the description at [wikipedia](https://en.wikipedia.org/wiki/Anscombe%27s_quartet)

## Examples from my own work

- Education
- Climate change
- US Election polls
- Airline traffic patterns
- Wages

## Education: OECD PISA

- OECD PISA survey ``the world's global metric for quality, equity and efficiency in school education".
- Workforce readiness of 15-year old students
- 500,000 students were tested across 65 countries and 18,000 schools
- Math, reading and science
- Data available from  [http://www.oecd.org/pisa](http://www.oecd.org/pisa/keyfindings/pisa-2012-results.htm)

##

```{r load_data, echo = FALSE, message = FALSE, warning = FALSE, results='hide', cache=FALSE}
student2012.sub <- readRDS("../data/student_sub.rds")
```

```{r mapdata, echo = FALSE, message = FALSE, warning = FALSE, results='hide', cache=FALSE}
world <- getMap(resolution = "low")
extractPolys <- function(p) {
  polys <- NULL
  for (i in 1:length(p)) {
    for (j in 1:length(p[[i]]@Polygons)) {
      x <- p[[i]]@Polygons[[j]]@coords
      polys$lon <- c(polys$lon, x[,1])
      polys$lat <- c(polys$lat, x[,2])
      polys$ID <- c(polys$ID, rep(p[[i]]@ID, nrow(x)))
      polys$region <- c(polys$region, rep(paste(p[[i]]@ID, j, sep="_"), nrow(x)))
      polys$order <- c(polys$order, 1:nrow(x))
    }
  }
  return(data.frame(polys))
}
polys <- extractPolys(world@polygons)

# Map theme
theme_map <- theme_bw()
theme_map$line <- element_blank()
theme_map$strip.text <- element_blank()
theme_map$axis.text <- element_blank()
theme_map$plot.title <- element_blank()
theme_map$axis.title <- element_blank()
theme_map$panel.border <- element_rect(colour = "grey90", size=1, fill=NA)
```

```{r dataprep, cache=FALSE, echo = FALSE, message = FALSE, warning = FALSE}
student2012.sub$ST04Q01 <- factor(student2012.sub$ST04Q01, 
  levels=c(1,2), labels=c("Female", "Male"))
```

```{r computemean, cache=FALSE, echo = FALSE, message = FALSE, warning = FALSE, error=FALSE, fig.width=6, fig.height=7}
# Calculate the statistics
student2012.stats <- student2012.sub %>% 
  group_by(CNT) %>%
  summarise(mathgap=mean(PV1MATH[ST04Q01=="Male"], na.rm=T)-
                    mean(PV1MATH[ST04Q01=="Female"], na.rm=T),
            wmathgap=weighted.mean(PV1MATH[ST04Q01=="Male"], 
                                   w=SENWGT_STU[ST04Q01=="Male"], na.rm=T)-
                     weighted.mean(PV1MATH[ST04Q01=="Female"],
                                   w=SENWGT_STU[ST04Q01=="Female"], na.rm=T))

# Compute confidence intervals
cifn <- function(d, i) {
  x <- d[i,]
  ci <- weighted.mean(x$PV1MATH[x$ST04Q01=="Male"], 
                                   w=x$SENWGT_STU[x$ST04Q01=="Male"], na.rm=T)-
                     weighted.mean(x$PV1MATH[x$ST04Q01=="Female"],
                                   w=x$SENWGT_STU[x$ST04Q01=="Female"], na.rm=T)
  ci
}
bootfn <- function(d) {
  r <- boot(d, statistic=cifn, R=100)
  l <- sort(r$t)[5]
  u <- sort(r$t)[95]
  ci <- c(l, u)
  return(ci)
}
#student2012.sub.summary.gap.boot <- ddply(student2012.sub, .(CNT), bootfn)
student2012.sub.summary.gap.boot <- student2012.sub %>% 
  split(.$CNT) %>% purrr::map(bootfn) %>% data.frame() %>%
  gather(CNT, value)
student2012.sub.summary.gap.boot$ci <- 
  rep(c("ml","mu"), length(unique(student2012.sub.summary.gap.boot$CNT)))
student2012.sub.summary.gap.boot.wide <- student2012.sub.summary.gap.boot %>% spread(ci, value)
student2012.sub.summary.gap <- merge(student2012.stats, student2012.sub.summary.gap.boot.wide)

# Match three digit codes to country names 
student2012.sub.summary.gap$name <- NA
for (i in 1:length(student2012.sub.summary.gap$name))  
  student2012.sub.summary.gap$name[i] <-
  isoToName(as.character(student2012.sub.summary.gap$CNT[i]))
# QCN is Shanghai, not whole of China - Don't know what country TAP is
student2012.sub.summary.gap$name[student2012.sub.summary.gap$CNT == "QCN"] <- isoToName("CHN")
student2012.sub.summary.gap$name[student2012.sub.summary.gap$CNT == "TAP"] <- "TAP"

# Make a categorical gap variable
#student2012.sub.summary.gap <-  student2012.sub.summary.gap %>% 
#  mutate(wmathgap_cat = cut(wmathgap, breaks=c(-10,-5, 5, 30), 
#                            labels=c("girls", "same", "boys")))
student2012.sub.summary.gap$wmathgap_cat <- "same"
student2012.sub.summary.gap$wmathgap_cat[student2012.sub.summary.gap$ml > 0] <- "boys"
student2012.sub.summary.gap$wmathgap_cat[student2012.sub.summary.gap$mu < 0] <- "girls"

# Set order of countries by math gap
student2012.sub.summary.gap$CNT <- factor(student2012.sub.summary.gap$CNT, 
      levels=student2012.sub.summary.gap$CNT[order(student2012.sub.summary.gap$wmathgap)])
student2012.sub.summary.gap$name <- factor(student2012.sub.summary.gap$name, 
      levels=student2012.sub.summary.gap$name[order(student2012.sub.summary.gap$wmathgap)])

# Plot
ggplot(data=student2012.sub.summary.gap) + 
  geom_hline(yintercept=0, colour="grey80") + coord_flip() + theme_bw() + 
  geom_point(aes(x=name, y=wmathgap, color=wmathgap_cat), size=3) + 
  geom_segment(aes(x=name, xend=name, y=ml, yend=mu, color=wmathgap_cat)) + 
  xlab("") +  
  scale_colour_manual("", values=c("boys"="skyblue", "girls"="pink", "same"="lightgreen")) +
  scale_y_continuous("Girls <----------> Boys", breaks=seq(-30, 30, 10), limits=c(-35, 35), 
                     labels=c(seq(30, 0, -10), seq(10, 30, 10))) + 
  theme(axis.text.x = element_text(size=5), axis.text.y = element_text(size=5), 
        axis.title = element_text(size=7), legend.text = element_text(size=5),
        legend.title = element_text(size=5))
```

##

```{r maps, cache=FALSE, echo = FALSE, message = FALSE, warning = FALSE, fig.width=8, fig.height=4}
polys <- polys %>% rename(name = ID)
student2012.sub.map <- left_join(student2012.sub.summary.gap, polys)
student2012.sub.map <- student2012.sub.map %>% arrange(region, order)

ggplot(data=polys) + 
  geom_path(aes(x=lon, y=lat, group=region, order=order), colour=I("grey90"), size=0.1) + 
  geom_polygon(data=student2012.sub.map, aes(x=lon, y=lat, group=region, order=order,  fill=wmathgap_cat)) +
  scale_fill_manual("Diff>5", values=c("boys"="skyblue", "girls"="pink", "same"="lightgreen")) + 
  scale_x_continuous(expand=c(0,0)) + scale_y_continuous(expand=c(0,0)) +
  coord_equal() + theme_map 
```

## What do we learn?

- Math gender gap is not universal
- Many countries have no substantial difference
- Reverse gap exists in surprising places
- Australia has a 10 point gap (10 points out of 1000 points)
- Individuals show different pattern, highest math score in US is by a girl
- Australia has a huge variation in scores, one of the highest countries, but also one of the lowest countries
- Reading gap is universal in favour of girls

## Carbon dioxide data

- Data is collected at a number of locations world wide. 
- See [Scripps Inst. of Oceanography](http://scrippsco2.ucsd.edu/data/atmospheric_co2) 
- Let's pull the data from the web and take a look ...
- 
- Recordings from South Pole (SPO), Kermadec Islands (KER), Mauna Loa Hawaii (MLF), La Jolla Pier, California (LJO), Point Barrow, Alaska (PTB).

##

```{r CO2, fig.width=10, fig.height=5, warning=FALSE, message=FALSE, echo=FALSE, cache=FALSE}
CO2.ptb<-read.table("http://scrippsco2.ucsd.edu/sites/default/files/data/flask_co2_and_isotopic/daily_co2/fldav_ptb.csv", sep=",", skip=69)
colnames(CO2.ptb)<-c("date", "time", "day", "decdate", "n", "flg", "co2")
CO2.ptb$lat<-71.3
CO2.ptb$lon<-(-156.6)
CO2.ptb$stn<-"ptb"

CO2.ljo<-read.table("http://scrippsco2.ucsd.edu/sites/default/files/data/flask_co2_and_isotopic/daily_co2/fldav_ljo.csv", sep=",", skip=69)
colnames(CO2.ljo)<-c("date", "time", "day", "decdate", "n", "flg", "co2")
CO2.ljo$lat<-32.9
CO2.ljo$lon<-(-117.3)
CO2.ljo$stn<-"ljo"

CO2.mlf<-read.table("http://scrippsco2.ucsd.edu/sites/default/files/data/flask_co2_and_isotopic/daily_co2/fldav_mlf.csv", sep=",", skip=69)
colnames(CO2.mlf)<-c("date", "time", "day", "decdate", "n", "flg", "co2")
CO2.mlf$lat<-19.5
CO2.mlf$lon<-(-155.6)
CO2.mlf$stn<-"mlf"

CO2.spo<-read.table("http://scrippsco2.ucsd.edu/sites/default/files/data/flask_co2_and_isotopic/daily_co2/fldav_spo.csv", sep=",", skip=69)
colnames(CO2.spo)<-c("date", "time", "day", "decdate", "n", "flg", "co2")
CO2.spo$lat<- (-90.0)
CO2.spo$lon<-0
CO2.spo$stn<-"spo"

CO2.ker<-read.table("http://scrippsco2.ucsd.edu/sites/default/files/data/flask_co2_and_isotopic/daily_co2/fldav_ker.csv", sep=",", skip=69)
colnames(CO2.ker)<-c("date", "time", "day", "decdate", "n", "flg", "co2")
CO2.ker$lat<-(-29.2)
CO2.ker$lon<-(-177.9)
CO2.ker$stn<-"ker"

CO2.all<-rbind(CO2.ker,CO2.ljo,CO2.mlf,CO2.ptb,CO2.spo)
CO2.all$date<-as.Date(CO2.all$date)

CO2.all$invlat=-1*CO2.all$lat
CO2.all$stn=reorder(CO2.all$stn,CO2.all$invlat)

CO2.all.loc <- rbind(CO2.ker[1,],CO2.ljo[1,],CO2.mlf[1,],CO2.ptb[1,],CO2.spo[1,])

p1 <- qplot(date, co2, data=subset(CO2.all, flg < 2), colour=stn, geom="line",xlab="Year",ylab="CO2 (ppm)") + 
		facet_wrap(~stn, ncol=1) + theme(axis.text.y=element_text(size = 6), legend.position="none")
p2 <- qplot(date, co2, data=subset(CO2.all, flg < 2), colour=stn, geom="line",xlab="Year",ylab="CO2 (ppm)") + 
  theme(axis.text.y=element_text(size = 6), legend.position="none")
grid.arrange(p1, p2, ncol=2)
```

## 

```{r CO2-locations, fig.width=10, fig.height=5, warning=FALSE, message=FALSE, echo=FALSE, cache=FALSE}
ggplot(data=polys) + 
  geom_path(aes(x=lon, y=lat, group=region, order=order), colour=I("grey90"), size=0.1) + 
  geom_point(data=CO2.all.loc, aes(x=lon, y=lat, group=1), colour="red", 
                      size=2, alpha=0) +
  geom_text(data=CO2.all.loc, aes(x=lon, y=lat, label=stn, group=1), 
            colour="orange", size=5) +
  coord_equal() + theme_map 
```

## What do we learn?

- CO$_2$ is increasing, and it looks like it is exponential increase. **I really expected that the concentration would have flattened out with all of the efforts to reduce carbon emissions.**
- The same trend is seen at every location - REALLY? Need some physics to understand this.
- Some stations show seasonal pattern - actually the more north the more seasonality - WHY?

## US Airline traffic

- ~15,000 flights a day
- April 1986 - present (2008)
- RITA - Research and Innovative Technology Administration (flight information, arrival delay, airline, plane id, ...)
- On time performance database - [http://www.transtats.bts.gov/](http://www.transtats.bts.gov/) - yes, you can download this yourself
- Analysis code examples on [https://github.com/heike/data-technologies](https://github.com/heike/data-technologies)

##

\centerline{\includegraphics[width=8in]{airlines1.pdf}}

##

\centerline{\includegraphics[width=8in]{airlines2.pdf}}

##

\centerline{\includegraphics[width=8in]{airlines3.pdf}}

##

\centerline{\includegraphics[width=8in]{airlines4.pdf}}

## What did we learn?

- Fly early in the day, early in the week or weekends (Saturday)
- Avoid ORD, JFK, LGA, EWR
- American Airlines filed for bankruptcy Nov 29, 2013. Mining publicly available data could have sounded the alarms several years in advance

## Wages

- 6402 observations on 888 high school dropouts, 1990-2002

```{r echo=FALSE}
library(HLMdiag)
data(wages)
glimpse(wages)
```

Source: [Singer and Willett](http://www.ats.ucla.edu/stat/examples/alda/)

##

```{r echo=FALSE, fig.align='center', fig.width=8, fig.height=6}
ggplot(wages, aes(x=exper, y=lnw)) + 
  geom_line(aes(group=id), alpha=0.3) +
  geom_smooth(se=F) +
  xlab("Year of experience") +
  ylab("Log of hourly wage")
```

## Video

\centerline{\includemovie[poster, text={\small (wages-increasing.mov)}]{181pt}{166pt}{wages-increasing.mov}}

## Video

\centerline{\includemovie[poster, text={\small (wages-decreasing.mov)}]{181pt}{166pt}{wages-decreasing.mov}}

## US Election

- They are in the middle of another LONG election
- Its coming to a close
- There is a lot of information about how people might vote
- We looked at how things progressed in 2008 election, in the months leading up to the vote
- We used web scrapers to pull polling data off web sites

## 

\centerline{\includegraphics[width=9in]{USelection.pdf}}

Pollsters operating in the US are not all impartial. 

## Your turn

\centerline{\bf Why make a plot of data??}

## Your turn

- What is a (data) plot?
- What are the three most important data plots?
- Is a plot a statistic?

## Your turn

How would you describe this plot?

```{r echo=FALSE}
pedestrian <- read_csv("../data/Pedestrian_Counts.csv",
      col_names=c("DateTime","SensorID","SensorName","Counts"), skip=1)
pedestrian$Date <- as.Date(substr(pedestrian$DateTime, 1, 11), format="%d-%b-%Y")
pedestrian$Year <- year(pedestrian$Date)
pedestrian$Month <- month(pedestrian$Date, label=TRUE, abbr=TRUE)
pedestrian$Day <- wday(pedestrian$Date, label=TRUE) # and re-order days
pedestrian$Day <- factor(pedestrian$Day, levels = levels(pedestrian$Day)[c(2:7, 1)])
pedestrian$Hour <- as.numeric(substr(pedestrian$DateTime, 13, 14))
pedestrian <- pedestrian %>% group_by(SensorID) %>% 
  mutate(Time=as.numeric(Date - min(Date))*24 + Hour)
pedestrian <- pedestrian %>% filter(Date >= as.Date("2013-01-01"))
ggplot(data=filter(pedestrian, SensorID==1), aes(factor(Hour), Counts)) +   geom_boxplot() +
  xlab("Hour") + ylab("Count") + theme(aspect.ratio=0.8) +
  ggtitle("Counts by hour")
```

## What about this one?

```{r echo=FALSE}
sensors <- read_csv("../data/Pedestrian_Sensor_Locations.csv")
map <- get_map(location=c(144.955, -37.81), zoom=14, maptype = "roadmap")
ggmap(map) + 
  geom_point(aes(x=Longitude, y=Latitude), data=sensors, size=3, color="darkblue") +
  xlab("") + ylab("") +
  ggtitle("Sensor locations")
```

## Using the package ggplot2

Elements of a plot

- data
- aesthetics: mapping of variables to graphical elements
- geom: type of plot structure to use
- transformations: log scale, ...

Additional components 

- layers: multiple geoms, multiple data sets, annotation
- facets: show subsets in different plots
- themes: modifying style

## Why use a grammar of graphics?

\centerline{\bf Variable in the data is directly mapped to an element in the plot}

## Resources

- [Cheat sheet](https://www.rstudio.com/wp-content/uploads/2015/08/ggplot2-cheatsheet.pdf)
- [ggplot2: Elegant Graphics for Data Analysis, Hadley Wickham](http://ggplot2.org/book/), [web site](http://ggplot2.org)
- [R Graphics Cookbook, Winston Chang](http://www.cookbook-r.com/Graphs/)
- [Naomi Robbins, Creating More Effective Graphs](http://www.nbr-graphs.com)
- [Antony Unwin, Graphical Data Analysis with R](https://www.crcpress.com/Graphical-Data-Analysis-with-R/Unwin/9781498715232)

## Share and share alike

This work is licensed under the Creative Commons Attribution-Noncommercial 3.0 United States License. To view a copy of this license, visit http://creativecommons.org/licenses/by-nc/ 3.0/us/ or send a letter to Creative Commons, 171 Second Street, Suite 300, San Francisco, California, 94105, USA.
